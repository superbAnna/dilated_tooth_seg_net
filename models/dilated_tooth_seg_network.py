import lightning as L
import torch.nn.functional as F
import torch
import torchmetrics as tm
import numpy as np
from torch import nn
from models.layer import BasicPointLayer, EdgeGraphConvBlock, DilatedEdgeGraphConvBlock, ResidualBasicPointLayer, \
    PointFeatureImportance, STNkd
from libs.pointops.functions import pointops


def prepare_pointops_format(positions, batch_size):
    """
    å°† [B, N, 3] æ ¼å¼çš„ä½ç½®æ•°æ®è½¬æ¢ä¸º pointops éœ€è¦çš„æ ¼å¼
    """
    B, N, _ = positions.shape
    # é‡å¡‘ä¸º [B*N, 3]
    positions_flat = positions.reshape(-1, 3).contiguous()
    # åˆ›å»º offset: [0, N, 2*N, ..., B*N]
    offset = torch.arange(0, (B+1)*N, N, dtype=torch.int32, device=positions.device)
    return positions_flat, offset


class BoundaryContrastiveLoss(nn.Module):
    def __init__(self, nsample=8, temperature=0.07):
        super().__init__()
        self.nsample = nsample
        self.temperature = temperature

    def forward(self, features, positions, labels):
        """
        Args:
            features: [B, N, C] ç‰¹å¾
            positions: [B, N, 3] ä½ç½®
            labels: [B, N] æ ‡ç­¾
        """
        B, N, C = features.shape
        # å‡†å¤‡ pointops æ ¼å¼
        positions_flat, offset = prepare_pointops_format(positions, B)
        labels_flat = labels.reshape(-1)  # [B*N]
        features_flat = features.reshape(-1, C)  # [B*N, C]

        # ä¸€æ¬¡æ€§æ£€æµ‹æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_mask = self._detect_boundary_points_vectorized(
            labels_flat, positions_flat, offset, B, N
        )

        if not boundary_mask.any():
            return torch.tensor(0.0, device=features.device, requires_grad=True)

        # è·å–è¾¹ç•Œç‚¹
        boundary_indices = torch.where(boundary_mask)[0]
        boundary_features = features_flat[boundary_indices]
        boundary_labels = labels_flat[boundary_indices]
        boundary_positions = positions_flat[boundary_indices]

        # è®¡ç®—è¾¹ç•Œç‚¹é—´çš„å¯¹æ¯”æŸå¤±
        loss = self._compute_contrastive_loss_vectorized(
            boundary_features, boundary_labels, boundary_positions
        )

        return loss

    def _detect_boundary_points_vectorized(self, labels_flat, positions_flat, offset, B, N, k=8):
        """ä½¿ç”¨ pointops å‘é‡åŒ–æ£€æµ‹è¾¹ç•Œç‚¹"""
        total_points = B * N

        # ä½¿ç”¨ pointops è¿›è¡Œ KNN æŸ¥è¯¢
        neighbor_idx, _ = pointops.knnquery(k+1, positions_flat, positions_flat, offset, offset)
        neighbor_idx = neighbor_idx[:, 1:]  # æ’é™¤è‡ªå·± [total_points, k]

        # å‘é‡åŒ–è®¡ç®—è¾¹ç•Œç‚¹
        # è·å–é‚»å±…æ ‡ç­¾
        neighbor_labels = labels_flat[neighbor_idx]  # [total_points, k]
        current_labels = labels_flat.unsqueeze(1)    # [total_points, 1]

        # è®¡ç®—ä¸åŒæ ‡ç­¾çš„æ•°é‡
        different_count = (neighbor_labels != current_labels).sum(dim=1)  # [total_points]

        # è¾¹ç•Œç‚¹åˆ¤æ–­ï¼šè¶…è¿‡ä¸€åŠé‚»å±…æ ‡ç­¾ä¸åŒ
        boundary_mask = different_count > (k / 2)

        return boundary_mask

    def _compute_contrastive_loss_vectorized(self, boundary_features, boundary_labels, boundary_positions):
        """å‘é‡åŒ–è®¡ç®—å¯¹æ¯”æŸå¤±"""
        M = boundary_features.shape[0]
        if M < 2:
            return torch.tensor(0.0, device=boundary_features.device, requires_grad=True)

        # å‡†å¤‡å•æ‰¹æ¬¡ offset
        offset_single = torch.tensor([0, M], dtype=torch.int32, device=boundary_positions.device)

        # è·å–è¾¹ç•Œç‚¹ä¹‹é—´çš„é‚»å±…
        neighbor_idx, _ = pointops.knnquery(
            min(self.nsample, M-1), boundary_positions, boundary_positions,
            offset_single, offset_single
        )

        # ç‰¹å¾å½’ä¸€åŒ–
        boundary_features = F.normalize(boundary_features, dim=-1)

        # å‘é‡åŒ–è®¡ç®—ç›¸ä¼¼åº¦
        anchor_features = boundary_features.unsqueeze(1)  # [M, 1, C]
        neighbor_features = boundary_features[neighbor_idx]  # [M, K, C]

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.sum(anchor_features * neighbor_features, dim=-1) / self.temperature  # [M, K]

        # è®¡ç®—æ­£æ ·æœ¬mask
        anchor_labels = boundary_labels.unsqueeze(1)  # [M, 1]
        neighbor_labels = boundary_labels[neighbor_idx]  # [M, K]
        pos_mask = (anchor_labels == neighbor_labels)  # [M, K]

        # è¿‡æ»¤æ‰æ²¡æœ‰æ­£è´Ÿæ ·æœ¬å¯¹æ¯”çš„ç‚¹
        has_pos = pos_mask.any(dim=1)
        has_neg = (~pos_mask).any(dim=1)
        valid_mask = has_pos & has_neg

        if not valid_mask.any():
            return torch.tensor(0.0, device=boundary_features.device, requires_grad=True)

        # åªè®¡ç®—æœ‰æ•ˆç‚¹çš„æŸå¤±
        sim_matrix = sim_matrix[valid_mask]  # [V, K]
        pos_mask = pos_mask[valid_mask]      # [V, K]

        # è®¡ç®— InfoNCE æŸå¤±
        exp_sim = torch.exp(sim_matrix)
        pos_exp = (exp_sim * pos_mask.float()).sum(dim=1)
        all_exp = exp_sim.sum(dim=1)

        loss = -torch.log(pos_exp / all_exp + 1e-8)
        return loss.mean()


# Bmiou
class BoundaryMIoU:
    @staticmethod
    def compute_boundary_miou(pred_labels, true_labels, positions, k=8):
        """
        è®¡ç®—è¾¹ç•Œç‚¹çš„MIoU
        Args:
            pred_labels: [B, N] é¢„æµ‹æ ‡ç­¾
            true_labels: [B, N] çœŸå®æ ‡ç­¾
            positions: [B, N, 3] ä½ç½®ä¿¡æ¯
        """
        B, N = pred_labels.shape

        # å‡†å¤‡ pointops æ ¼å¼
        positions_flat, offset = prepare_pointops_format(positions, B)
        pred_labels_flat = pred_labels.reshape(-1)
        true_labels_flat = true_labels.reshape(-1)

        # å‘é‡åŒ–æ£€æµ‹è¾¹ç•Œç‚¹
        boundary_mask = BoundaryMIoU._detect_boundary_points_vectorized(
            true_labels_flat, positions_flat, offset, k
        )

        if not boundary_mask.any():
            return torch.tensor(0.0, device=pred_labels.device)

        # è·å–è¾¹ç•Œç‚¹çš„æ ‡ç­¾
        boundary_pred = pred_labels_flat[boundary_mask]
        boundary_true = true_labels_flat[boundary_mask]

        # è®¡ç®—è¾¹ç•Œç‚¹çš„ç±»åˆ«èŒƒå›´
        unique_true_labels = torch.unique(boundary_true)

        if len(unique_true_labels) <= 1:
            return torch.tensor(0.0, device=pred_labels.device)

        # è®¡ç®—MIoU
        return BoundaryMIoU._compute_miou_for_classes(
            boundary_pred, boundary_true, unique_true_labels
        )

    @staticmethod
    def _detect_boundary_points_vectorized(labels_flat, positions_flat, offset, k=8):
        """ä½¿ç”¨ pointops å‘é‡åŒ–æ£€æµ‹è¾¹ç•Œç‚¹"""
        # ä½¿ç”¨ pointops è¿›è¡Œ KNN æŸ¥è¯¢
        neighbor_idx, _ = pointops.knnquery(k+1, positions_flat, positions_flat, offset, offset)
        neighbor_idx = neighbor_idx[:, 1:]  # æ’é™¤è‡ªå·±

        # å‘é‡åŒ–è¾¹ç•Œæ£€æµ‹
        neighbor_labels = labels_flat[neighbor_idx]
        current_labels = labels_flat.unsqueeze(1)
        different_count = (neighbor_labels != current_labels).sum(dim=1)

        return different_count > (k / 2)

    @staticmethod
    def _compute_miou_for_classes(pred_labels, true_labels, class_labels):
        """è®¡ç®—æŒ‡å®šç±»åˆ«çš„MIoU"""
        ious = []

        for cls in class_labels:
            pred_mask = (pred_labels == cls)
            true_mask = (true_labels == cls)

            intersection = (pred_mask & true_mask).sum().float()
            union = (pred_mask | true_mask).sum().float()

            if union > 0:
                iou = intersection / union
                ious.append(iou)

        return torch.stack(ious).mean() if ious else torch.tensor(0.0, device=pred_labels.device)


class BoundaryAwareMultiScaleFusion(nn.Module):
    """
    æ”¹è¿›ç‰ˆè¾¹ç•Œæ„ŸçŸ¥å¤šå°ºåº¦èåˆæ¨¡å—
    """
    def __init__(self, feat_dims, n_scales=3, reduce_dim=256):
        """
        Args:
            feat_dims: list of int, å„å°ºåº¦ç‰¹å¾ç»´åº¦ [C_local, C_mid, C_global]
            n_scales: å°ºåº¦æ•°é‡
            reduce_dim: ç»Ÿä¸€ç‰¹å¾ç»´åº¦
        """
        super().__init__()
        self.n_scales = n_scales

        # ç‰¹å¾ç»´åº¦å¯¹é½
        self.feat_projs = nn.ModuleList([
            nn.Linear(dim, reduce_dim) for dim in feat_dims
        ])

        # è¾¹ç•Œç‰¹å¾æå–
        self.boundary_encoder = nn.Sequential(
            nn.Linear(3, 64),  # 3ä¸ªè¾¹ç•Œç‰¹å¾
            nn.ReLU(),
            nn.Linear(64, 128)
        )

        # æ³¨æ„åŠ›æƒé‡ç”Ÿæˆï¼ˆæ”¹è¿›ç‰ˆï¼‰
        self.attention = nn.Sequential(
            nn.Linear(reduce_dim + 128, 256),  # ç‰¹å¾ + è¾¹ç•Œç¼–ç 
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, n_scales)
        )

        # æœ€ç»ˆèåˆ
        self.output_proj = nn.Sequential(
            nn.Linear(reduce_dim, reduce_dim),
            nn.ReLU(),
            nn.Linear(reduce_dim, reduce_dim)
        )

    def extract_boundary_info(self, logits, labels, pos, use_gt=True):
        """æå–è¾¹ç•Œä¿¡æ¯"""
        B, N = labels.shape if use_gt else logits.shape[:2]

        # ä½¿ç”¨GTæˆ–é¢„æµ‹æ ‡ç­¾
        target_labels = labels if use_gt else torch.argmax(logits, dim=-1)

        positions_flat, offset = prepare_pointops_format(pos, B)
        labels_flat = target_labels.reshape(-1)

        # KNNæ£€æµ‹è¾¹ç•Œ
        neighbor_idx, _ = pointops.knnquery(9, positions_flat, positions_flat, offset, offset)
        neighbor_idx = neighbor_idx[:, 1:]

        neighbor_labels = labels_flat[neighbor_idx]
        current_labels = labels_flat.unsqueeze(1)
        different_ratio = (neighbor_labels != current_labels).float().mean(dim=1)
        boundary_score = different_ratio.reshape(B, N)

        # é¢„æµ‹ç½®ä¿¡åº¦å’Œç†µ
        probs = F.softmax(logits, dim=-1)
        confidence = probs.max(dim=-1)[0]
        entropy = -(probs * torch.log(probs + 1e-8)).sum(dim=-1) / np.log(probs.shape[-1])

        return torch.stack([boundary_score, confidence, entropy], dim=-1)  # [B, N, 3]

    def forward(self, feats, logits, labels, pos):
        """
        Args:
            feats: list of [B, N, C_i], å¤šå°ºåº¦ç‰¹å¾
            logits: [B, N, num_classes] æˆ– [B, C, N]
            labels: [B, N] GTæ ‡ç­¾ï¼ˆè®­ç»ƒï¼‰æˆ–Noneï¼ˆæ¨ç†ï¼‰
            pos: [B, N, 3]
        Returns:
            fused_feat: [B, N, reduce_dim]
        """
        B, N = pos.shape[:2]

        # ç»´åº¦è½¬æ¢
        if logits.dim() == 3 and logits.shape[1] != N:
            logits = logits.transpose(1, 2)  # [B, C, N] -> [B, N, C]

        # 1. ç‰¹å¾æŠ•å½±å¯¹é½
        feats_proj = [proj(f) for proj, f in zip(self.feat_projs, feats)]  # æ¯ä¸ª [B, N, reduce_dim]
        feats_stack = torch.stack(feats_proj, dim=2)  # [B, N, n_scales, reduce_dim]

        # 2. æå–è¾¹ç•Œä¿¡æ¯
        use_gt = (labels is not None) and self.training
        boundary_info = self.extract_boundary_info(
            logits, labels if use_gt else None, pos, use_gt=use_gt
        )  # [B, N, 3]

        # 3. è¾¹ç•Œç‰¹å¾ç¼–ç 
        boundary_encoding = self.boundary_encoder(boundary_info)  # [B, N, 128]

        # 4. ç”Ÿæˆæ³¨æ„åŠ›æƒé‡
        # ä½¿ç”¨å¹³å‡æ± åŒ–çš„å…¨å±€ç‰¹å¾ + è¾¹ç•Œç¼–ç 
        global_feat = feats_stack.mean(dim=2)  # [B, N, reduce_dim]
        attn_input = torch.cat([global_feat, boundary_encoding], dim=-1)
        attn_weights = self.attention(attn_input)  # [B, N, n_scales]
        attn_weights = F.softmax(attn_weights, dim=-1)

        # 5. åŠ æƒèåˆ
        attn_weights_exp = attn_weights.unsqueeze(-1)  # [B, N, n_scales, 1]
        fused_feat = (feats_stack * attn_weights_exp).sum(dim=2)  # [B, N, reduce_dim]

        # 6. è¾“å‡ºæŠ•å½±
        output = self.output_proj(fused_feat) + global_feat

        return output, attn_weights  # è¿”å›æƒé‡ç”¨äºå¯è§†åŒ–


class DilatedToothSegmentationNetwork(nn.Module):
    def __init__(self, num_classes=17, feature_dim=24):
        """
        :param num_classes: Number of classes to predict
        """
        super(DilatedToothSegmentationNetwork, self).__init__()
        self.num_classes = num_classes

        self.stnkd = STNkd(k=24)

        self.edge_graph_conv_block1 = EdgeGraphConvBlock(in_channels=feature_dim, out_channels=24, k=32,
                                                         hidden_channels=24,
                                                         edge_function="local_global")
        self.edge_graph_conv_block2 = EdgeGraphConvBlock(in_channels=24, out_channels=24, k=32,
                                                         hidden_channels=24,
                                                         edge_function="local_global")
        self.edge_graph_conv_block3 = EdgeGraphConvBlock(in_channels=24, out_channels=24, k=32,
                                                         hidden_channels=24,
                                                         edge_function="local_global")

        self.local_hidden_layer = BasicPointLayer(in_channels=24 * 3, out_channels=60)

        self.dilated_edge_graph_conv_block1 = DilatedEdgeGraphConvBlock(in_channels=60, hidden_channels=60,
                                                                        out_channels=60, k=32,
                                                                        dilation_k=200, edge_function="local_global")
        self.dilated_edge_graph_conv_block2 = DilatedEdgeGraphConvBlock(in_channels=60, hidden_channels=60,
                                                                        out_channels=60, k=32,
                                                                        dilation_k=900, edge_function="local_global")
        self.dilated_edge_graph_conv_block3 = DilatedEdgeGraphConvBlock(in_channels=60, hidden_channels=60,
                                                                        out_channels=60, k=32,
                                                                        dilation_k=1800, edge_function="local_global")

        self.bamsf = BoundaryAwareMultiScaleFusion(
            feat_dims=[72, 60, 180],  # x1+x2+x3=72, dilatedå„60
            n_scales=3,
            reduce_dim=256
        )
        # ä¸´æ—¶åˆ†ç±»å¤´ï¼ˆç”¨äºBAMSFçš„è¾¹ç•Œæ£€æµ‹ï¼‰
        self.temp_classifier = nn.Sequential(
            nn.Linear(240, 128),
            nn.LayerNorm(128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )

        # ç‰¹å¾å¤„ç†å’Œåˆ†ç±»å¤´
        self.feature_importance = PointFeatureImportance(in_channels=256)
        self.res_block1 = ResidualBasicPointLayer(
            in_channels=256, out_channels=384, hidden_channels=384
        )
        self.res_block2 = ResidualBasicPointLayer(
            in_channels=384, out_channels=256, hidden_channels=256
        )
        self.out = BasicPointLayer(in_channels=256, out_channels=num_classes, is_out=True)

        self.dropout2 = nn.Dropout(0.15)
        self.dropout3 = nn.Dropout(0.3)

    def forward(self, x, pos, labels=None):
        # precompute pairwise distance of points
        cd = torch.cdist(pos, pos)
        x = self.stnkd(x)
        # å±€éƒ¨ç‰¹å¾
        x1, _ = self.edge_graph_conv_block1(x, pos)
        x2, _ = self.edge_graph_conv_block2(x1)
        x3, _ = self.edge_graph_conv_block3(x2)

        x_local = torch.cat([x1, x2, x3], dim=2)

        x_mid = self.local_hidden_layer(x_local)

        x_d1, _ = self.dilated_edge_graph_conv_block1(x_mid, pos, cd=cd)
        x_d2, _ = self.dilated_edge_graph_conv_block2(x_d1, pos, cd=cd)
        x_d3, _ = self.dilated_edge_graph_conv_block3(x_d2, pos, cd=cd)
        x_global = torch.cat([x_d1, x_d2, x_d3], dim=2)
        x_temp = torch.cat([x_mid, x_d1, x_d2, x_d3], dim=2)  # [B, N, 240]
        logits_temp = self.temp_classifier(x_temp)  # [B, N, num_classes]

        # ===== 5. è¾¹ç•Œæ„ŸçŸ¥å¤šå°ºåº¦èåˆï¼ˆBAMSFï¼‰=====
        feats = [x_local, x_mid, x_global]  # 3ä¸ªä¸åŒå°ºåº¦çš„ç‰¹å¾
        x_fused, attn_weights = self.bamsf(
            feats, logits_temp, labels, pos
        )  # [B, N, 256], [B, N, 3]
        x_fused = self.dropout2(x_fused)
        # ===== 6. ç‰¹å¾å¤„ç†å’Œåˆ†ç±» =====
        x = self.feature_importance(x_fused)
        x = self.res_block1(x)
        features = self.res_block2(x)
        features = self.dropout3(features)
        seg_pred = self.out(features)
        return seg_pred, features, x_fused


class LitDilatedToothSegmentationNetwork(L.LightningModule):
    def __init__(self, boundary_contrast_weight=0.8, enable_boundary_loss_threshold=0.60,
                 stability_window=3,
                 stability_tolerance=0.02,
                 max_train_val_gap=0.35):
        super().__init__()
        self.model = DilatedToothSegmentationNetwork(num_classes=17, feature_dim=24)
        # æŸå¤±å‡½æ•°
        self.seg_loss = nn.CrossEntropyLoss()
        self.boundary_contrast_loss = BoundaryContrastiveLoss(nsample=8, temperature=0.07)
        self.boundary_contrast_weight = boundary_contrast_weight
        # è¾¹ç•ŒæŸå¤±åŠ¨æ€æ¿€æ´»å‚æ•°
        self.enable_boundary_loss_threshold = enable_boundary_loss_threshold
        self.boundary_loss_enabled = False
        self.stability_window = stability_window
        self.stability_tolerance = stability_tolerance
        self.max_train_val_gap = max_train_val_gap
        # è®°å½•å†å²æŒ‡æ ‡
        self.recent_val_mious = []
        self.best_val_miou = 0.0
        # ä¸»è¦æŒ‡æ ‡
        self.train_acc = tm.Accuracy(task="multiclass", num_classes=17)
        self.val_acc = tm.Accuracy(task="multiclass", num_classes=17)
        self.train_miou = tm.JaccardIndex(task="multiclass", num_classes=17)
        self.val_miou = tm.JaccardIndex(task="multiclass", num_classes=17)
        self.test_acc = tm.Accuracy(task="multiclass", num_classes=17)
        self.test_miou = tm.JaccardIndex(task="multiclass", num_classes=17)

        self.save_hyperparameters()

    def training_step(self, batch, batch_idx):
        pos, x, y = batch
        B, N, C = x.shape
        x = x.float()
        y = y.reshape(B, N).long()
        # å‰å‘
        seg_pred, features, x_fused = self.model(x, pos, labels=y)
        seg_pred = seg_pred.transpose(2, 1)
        # è®¡ç®—æŸå¤±
        seg_loss = self.seg_loss(seg_pred, y)
        # åŠ¨æ€å†³å®šæ˜¯å¦ä½¿ç”¨è¾¹ç•ŒæŸå¤±
        if self.boundary_loss_enabled:
            boundary_loss1 = self.boundary_contrast_loss(x_fused, pos, y)
            boundary_loss2 = self.boundary_contrast_loss(features, pos, y)
            boundary_loss = 0.5 * (boundary_loss1 + boundary_loss2)

            total_loss = seg_loss + self.boundary_contrast_weight * boundary_loss
        else:
            boundary_loss = torch.tensor(0.0, device=seg_loss.device)
            total_loss = seg_loss

        # è®¡ç®—æŒ‡æ ‡
        self.train_acc(seg_pred, y)
        self.train_miou(seg_pred, y)
        # è®¡ç®—BMIoU
        pred_labels = torch.argmax(seg_pred, dim=1)
        bmiou = BoundaryMIoU.compute_boundary_miou(pred_labels, y, pos)
        # æ—¥å¿—è®°å½•
        self.log("train_acc", self.train_acc, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("train_miou", self.train_miou, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("train_bmiou", bmiou, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("train_loss", total_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("train_seg_loss", seg_loss, on_step=False, on_epoch=True, sync_dist=True)
        self.log("train_boundary_loss", boundary_loss, on_step=False, on_epoch=True, sync_dist=True)
        self.log("boundary_loss_active", float(self.boundary_loss_enabled), on_step=False, on_epoch=True, sync_dist=True)
        return total_loss

    def validation_step(self, batch, batch_idx):
        pos, x, y = batch
        B, N, C = x.shape
        x = x.float()
        y = y.reshape(B, N).long()

        # ä¸»æ¨¡å‹å‰å‘ä¼ æ’­
        seg_pred, features, x_fused = self.model(x, pos, labels=y)
        seg_pred = seg_pred.transpose(2, 1)

        # ä¸»æ¨¡å‹æŸå¤±
        seg_loss = self.seg_loss(seg_pred, y)
        self.log("val_seg_loss", seg_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)

        if self.boundary_loss_enabled:
            boundary_loss1 = self.boundary_contrast_loss(x_fused, pos, y)
            boundary_loss2 = self.boundary_contrast_loss(features, pos, y)
            boundary_loss = 0.5 * (boundary_loss1 + boundary_loss2)

            self.log("val_seg_loss", seg_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)

        else:
            boundary_loss = torch.tensor(0.0, device=seg_loss.device)

        total_loss = seg_loss
        self.log("val_loss", total_loss, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        # ä¸»æ¨¡å‹æŒ‡æ ‡
        self.val_acc(seg_pred, y)
        self.val_miou(seg_pred, y)
        # ä¸»æ¨¡å‹BMIoU
        pred_labels = torch.argmax(seg_pred, dim=1)
        bmiou = BoundaryMIoU.compute_boundary_miou(pred_labels, y, pos)

        # ä¸»æ¨¡å‹æ—¥å¿—
        self.log("val_acc", self.val_acc, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("val_miou", self.val_miou, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)
        self.log("val_bmiou", bmiou, prog_bar=True, on_step=False, on_epoch=True, sync_dist=True)

        return total_loss

    def on_validation_epoch_end(self):
        """åœ¨éªŒè¯epochç»“æŸæ—¶æ£€æŸ¥æ˜¯å¦å¯ç”¨è¾¹ç•ŒæŸå¤±"""
        if not self.trainer.is_global_zero:
            return
        # è·å–å½“å‰éªŒè¯æŒ‡æ ‡
        current_val_miou = self.trainer.logged_metrics.get('val_miou', 0.0)
        current_train_miou = self.trainer.logged_metrics.get('train_miou', 0.0)

        # æ›´æ–°å†å²è®°å½•
        self.recent_val_mious.append(float(current_val_miou))
        if len(self.recent_val_mious) > self.stability_window:
            self.recent_val_mious.pop(0)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¯ç”¨è¾¹ç•ŒæŸå¤±
        if not self.boundary_loss_enabled and len(self.recent_val_mious) >= self.stability_window:
            # æ¡ä»¶1: éªŒè¯mIoUè¾¾åˆ°é˜ˆå€¼
            condition1 = current_val_miou >= self.enable_boundary_loss_threshold

            # æ¡ä»¶2: éªŒè¯mIoUç¨³å®šï¼ˆæ ‡å‡†å·®å°äºå®¹å¿åº¦ï¼‰
            miou_std = np.std(self.recent_val_mious)
            condition2 = miou_std < self.stability_tolerance

            if condition1 and condition2:
                self.boundary_loss_enabled = True
                print(f"\n{'='*60}")
                print(f"ğŸ¯ Boundary Loss ENABLED at Epoch {self.trainer.current_epoch + 1}")
                print(f"  Val mIoU: {current_val_miou:.4f} (threshold: {self.enable_boundary_loss_threshold})")
                print(f"  Stability: {miou_std:.4f} (tolerance: {self.stability_tolerance})")
                print(f"{'='*60}\n")

        # æ›´æ–°æœ€ä½³éªŒè¯mIoU
        if current_val_miou > self.best_val_miou:
            self.best_val_miou = current_val_miou

    def test_step(self, batch, batch_idx):
        pos, x, y = batch
        B, N, C = x.shape
        x = x.float()
        y = y.reshape(B, N).long()

        # ä¸»æ¨¡å‹å‰å‘ä¼ æ’­
        seg_pred, features, x_fused = self.model(x, pos, labels=y)
        seg_pred = seg_pred.transpose(2, 1)

        # ä¸»æ¨¡å‹æŸå¤±
        seg_loss = self.seg_loss(seg_pred, y)
        boundary_loss = self.boundary_contrast_loss(features, pos, y)
        total_loss = seg_loss + self.boundary_contrast_weight * boundary_loss

        # ä¸»æ¨¡å‹æŒ‡æ ‡
        self.test_acc(seg_pred, y)
        self.test_miou(seg_pred, y)

        # ä¸»æ¨¡å‹BMIoU
        pred_labels = torch.argmax(seg_pred, dim=1)
        bmiou = BoundaryMIoU.compute_boundary_miou(pred_labels, y, pos)

        # ä¸»æ¨¡å‹æ—¥å¿—
        self.log("test_acc", self.test_acc, prog_bar=True, on_step=False, on_epoch=True)
        self.log("test_miou", self.test_miou, prog_bar=True, on_step=False, on_epoch=True)
        self.log("test_bmiou", bmiou, prog_bar=True, on_step=False, on_epoch=True)
        self.log("test_loss", total_loss, prog_bar=True, on_step=False, on_epoch=True)

        return total_loss

    def on_train_epoch_start(self):
        """è®­ç»ƒepochå¼€å§‹æ—¶é‡ç½®æŒ‡æ ‡"""
        self.train_acc.reset()
        self.train_miou.reset()

    def on_validation_epoch_start(self):
        """éªŒè¯epochå¼€å§‹æ—¶é‡ç½®æŒ‡æ ‡"""
        self.val_acc.reset()
        self.val_miou.reset()

    def predict_labels(self, data):
        with torch.autocast(device_type="cuda" if self.device.type == "cuda" else "cpu"):
            with torch.no_grad():
                pos, x, y = data
                pos = pos.unsqueeze(0).to(self.device)
                x = x.unsqueeze(0).to(self.device)
                B, N, C = x.shape
                x = x.float()

                seg_pred, _, _ = self.model(x, pos, labels=y)
                pred_labels = torch.argmax(seg_pred, dim=1)

                return pred_labels.squeeze()

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, betas=(0.9, 0.999), weight_decay=1e-5)
        sch = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-5)

        return {
            "optimizer": optimizer,
            "lr_scheduler": {
                "scheduler": sch,
                "monitor": "train_loss",
            }
        }
